import Foundation
import Speech
import AVFoundation
import Combine

class VoiceAssistant: NSObject, ObservableObject, AVAudioPlayerDelegate {
    @Published var isListening = false
    @Published var isSpeaking = false
    @Published var conversationActive = false
    @Published var lastTranscript = ""
    
    private var audioPlayer: AVAudioPlayer?
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    private let audioSession = AVAudioSession.sharedInstance()
    
    private var conversationTimer: Timer?
    private var drowsySessionActive = false
    private var conversationStartTime: Date?
    private let conversationDuration: TimeInterval = 60 // 1 minute per session
    
    private let networkManager = NetworkManager.shared
    private var currentDriverState = "Normal"
    
    override init() {
        super.init()
        print("üîß [INIT] VoiceAssistant initializing...")
        setupAudioSession()
        requestMicrophonePermission()
        requestSpeechPermission()
        print("‚úÖ [INIT] VoiceAssistant initialized")
    }
    
    // MARK: - Audio Session Setup
    private func setupAudioSession() {
        print("üîß [AUDIO] Setting up audio session...")
        do {
            try audioSession.setCategory(.playAndRecord, options: [.duckOthers])
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
            print("‚úÖ [AUDIO] Audio session configured for playback and recording")
        } catch {
            print("‚ùå [AUDIO] Audio session error: \(error)")
        }
    }
    
    // MARK: - Permissions
    private func requestMicrophonePermission() {
        print("üîß [PERMISSIONS] Requesting microphone permission...")
        AVAudioApplication.requestRecordPermission { granted in
            DispatchQueue.main.async {
                if granted {
                    print("‚úÖ [PERMISSIONS] Microphone permission granted")
                } else {
                    print("‚ùå [PERMISSIONS] Microphone permission denied")
                }
            }
        }
    }
    
    private func requestSpeechPermission() {
        print("üîß [PERMISSIONS] Requesting speech recognition permission...")
        SFSpeechRecognizer.requestAuthorization { status in
            DispatchQueue.main.async {
                switch status {
                case .authorized:
                    print("‚úÖ [PERMISSIONS] Speech recognition authorized")
                case .denied:
                    print("‚ùå [PERMISSIONS] Speech recognition denied")
                case .restricted:
                    print("‚ö†Ô∏è [PERMISSIONS] Speech recognition restricted")
                case .notDetermined:
                    print("‚ö†Ô∏è [PERMISSIONS] Speech recognition not determined")
                @unknown default:
                    print("‚ö†Ô∏è [PERMISSIONS] Speech recognition unknown status")
                }
            }
        }
    }
    
    // MARK: - Drowsy Conversation Session
    /// Start a 1-minute drowsy conversation session
    func startDrowsyConversation(driverState: String) {
        guard !drowsySessionActive else {
            print("‚ö†Ô∏è [DROWSY] Drowsy conversation already active")
            return
        }
        
        print("üö® [DROWSY] ====== DROWSY CONVERSATION STARTED ======")
        print("üö® [DROWSY] Driver State: \(driverState)")
        print("üö® [DROWSY] Conversation Duration: \(conversationDuration)s")
        drowsySessionActive = true
        conversationActive = true
        conversationStartTime = Date()
        currentDriverState = driverState
        
        // Request first AI response
        print("üö® [DROWSY] Requesting initial AI response...")
        requestChatResponse(message: nil, driverState: driverState)
        
        // Start timer to check if conversation should continue after 1 minute
        startConversationTimer()
    }
    
    private func startConversationTimer() {
        conversationTimer?.invalidate()
        print("‚è±Ô∏è [TIMER] Setting up \(conversationDuration)s timer")
        conversationTimer = Timer.scheduledTimer(withTimeInterval: conversationDuration, repeats: false) { [weak self] _ in
            print("‚è±Ô∏è [TIMER] Timer fired - checking if driver still drowsy")
            self?.checkAndContinueConversation()
        }
    }
    
    private func checkAndContinueConversation() {
        print("‚è±Ô∏è [TIMER] Conversation minute elapsed. Checking if driver still drowsy...")
        print("‚è±Ô∏è [TIMER] Current driver state: \(currentDriverState)")
        
        // If the driver is no longer drowsy, end session
        if currentDriverState.lowercased() != "drowsy" {
            print("‚úÖ [DROWSY] Driver no longer drowsy. Ending conversation.")
            endDrowsyConversation()
            return
        }
        
        // Continue for another minute
        print("‚ö†Ô∏è [DROWSY] Driver still drowsy. Continuing conversation for another minute...")
        conversationStartTime = Date()
        requestChatResponse(message: nil, driverState: "Drowsy")
        startConversationTimer()
    }
    
    func endDrowsyConversation() {
        print("üõë [DROWSY] ====== DROWSY CONVERSATION ENDED ======")
        drowsySessionActive = false
        conversationActive = false
        conversationTimer?.invalidate()
        conversationTimer = nil
        stopListening()
    }
    
    // MARK: - Chat API
    private func requestChatResponse(message: String?, driverState: String) {
        let displayMessage = message ?? "(auto-initiated)"
        print("üì§ [API] Sending chat request:")
        print("üì§ [API]   Message: \(displayMessage)")
        print("üì§ [API]   Driver State: \(driverState)")
        
        let payload: [String: Any] = [
            "message": message ?? "",
            "driverState": driverState
        ]
        
        guard let url = URL(string: "http://10.206.38.172:3000/api/chat") else {
            print("‚ùå [API] Invalid chat URL")
            return
        }
        
        print("üì§ [API] URL: \(url)")
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        
        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: payload)
            print("üì§ [API] Request body prepared")
            
            URLSession.shared.dataTask(with: request) { [weak self] data, response, error in
                if let error = error {
                    print("‚ùå [API] Chat request error: \(error.localizedDescription)")
                    return
                }
                
                // Log HTTP response status
                if let httpResponse = response as? HTTPURLResponse {
                    print("ÔøΩ [API] HTTP Status: \(httpResponse.statusCode)")
                }
                
                guard let data = data else {
                    print("‚ùå [API] No data from chat endpoint")
                    return
                }
                
                print("üì• [API] Received \(data.count) bytes")
                
                // Log the raw response for debugging
                if let jsonString = String(data: data, encoding: .utf8) {
                    print("ÔøΩ [API] Raw response:\n\(jsonString)")
                }
                
                do {
                    let result = try JSONDecoder().decode(ChatResponse.self, from: data)
                    print("‚úÖ [API] Successfully decoded chat response")
                    print("‚úÖ [API] Reply: \(result.reply)")
                    print("‚úÖ [API] Audio URL: \(result.audioUrl)")
                    DispatchQueue.main.async {
                        self?.playAudio(from: result.audioUrl)
                    }
                } catch {
                    print("‚ùå [API] Failed to decode chat response: \(error)")
                    // Try to parse as error response
                    if let errorResponse = try? JSONDecoder().decode([String: String].self, from: data) {
                        print("‚ùå [API] Error response from server: \(errorResponse)")
                    }
                }
            }.resume()
        } catch {
            print("‚ùå [API] Failed to encode chat request: \(error)")
        }
    }
    
    // MARK: - Audio Playback
    private func playAudio(from audioUrl: String) {
        guard let fullUrl = URL(string: "http://10.206.38.172:3000\(audioUrl)") else {
            print("‚ùå [AUDIO] Invalid audio URL: \(audioUrl)")
            return
        }
        
        print("üîä [AUDIO] Fetching audio from: \(fullUrl)")
        
        URLSession.shared.dataTask(with: fullUrl) { [weak self] data, response, error in
            guard let self = self, let data = data, error == nil else {
                print("‚ùå [AUDIO] Audio fetch failed: \(error?.localizedDescription ?? "Unknown error")")
                return
            }
            
            print("üîä [AUDIO] Received \(data.count) bytes of audio data")
            
            do {
                let player = try AVAudioPlayer(data: data, fileTypeHint: AVFileType.mp3.rawValue)
                DispatchQueue.main.async {
                    print("üîä [AUDIO] Audio player created successfully")
                    self.audioPlayer = player
                    self.audioPlayer?.delegate = self
                    self.isSpeaking = true
                    print("‚ñ∂Ô∏è [AUDIO] Starting playback...")
                    self.audioPlayer?.play()
                }
            } catch {
                print("‚ùå [AUDIO] Failed to create audio player: \(error)")
            }
        }.resume()
    }
    
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        DispatchQueue.main.async {
            self.isSpeaking = false
            print("‚èπÔ∏è [AUDIO] Audio playback finished")
            
            // Start listening for driver response
            if self.drowsySessionActive {
                print("üé§ [AUDIO] Audio finished, starting to listen for driver response...")
                self.startListening()
            }
        }
    }
    
    // MARK: - Speech Recognition
    func startListening() {
        guard !isListening else {
            print("‚ö†Ô∏è [SPEECH] Already listening")
            return
        }
        guard let recognizer = speechRecognizer, recognizer.isAvailable else {
            print("‚ùå [SPEECH] Speech recognizer not available")
            return
        }
        
        print("üé§ [SPEECH] Starting to listen for driver response...")
        
        do {
            try audioEngine.start()
            recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
            guard let recognitionRequest = recognitionRequest else {
                print("‚ùå [SPEECH] Failed to create recognition request")
                return
            }
            
            recognitionRequest.shouldReportPartialResults = true
            
            recognitionTask = recognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
                guard let self = self else { return }
                
                if let error = error {
                    print("‚ùå [SPEECH] Recognition error: \(error)")
                    self.stopListening()
                    return
                }
                
                if let result = result {
                    let transcript = result.bestTranscription.formattedString
                    DispatchQueue.main.async {
                        self.lastTranscript = transcript
                        print("üéôÔ∏è [SPEECH] Partial: \(transcript)")
                    }
                    
                    // If final result, send to chat
                    if result.isFinal {
                        print("üéôÔ∏è [SPEECH] Final transcript: \(transcript)")
                        self.stopListening()
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                            print("üì§ [SPEECH] Sending driver response to chat API")
                            self.requestChatResponse(message: transcript, driverState: self.currentDriverState)
                        }
                    }
                }
            }
            
            // Configure audio input
            let inputNode = audioEngine.inputNode
            let recordingFormat = inputNode.outputFormat(forBus: 0)
            print("üé§ [SPEECH] Audio format: \(recordingFormat)")
            inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
                recognitionRequest.append(buffer)
            }
            
            audioEngine.prepare()
            try audioEngine.start()
            isListening = true
            print("‚úÖ [SPEECH] Listening active")
        } catch {
            print("‚ùå [SPEECH] Audio engine error: \(error)")
        }
    }
    
    func stopListening() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
        isListening = false
        print("üé§ [SPEECH] Stopped listening")
    }
}

// MARK: - Models
struct ChatResponse: Codable {
    let reply: String
    let audioUrl: String
}
